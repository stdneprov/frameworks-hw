{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3912020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy scipy matplotlib scikit-learn pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f6503",
   "metadata": {},
   "source": [
    "# Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c55b7168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, r2_score, recall_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d206d643",
   "metadata": {},
   "source": [
    "# Реализация структуры данных дерева"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0012a6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af75d401",
   "metadata": {},
   "source": [
    "# Собственная реализация классификатора дерева решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    def _gini_impurity(self, counts):\n",
    "        n = counts.sum()\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        probs = counts / n\n",
    "        return 1.0 - np.dot(probs, probs)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, m = X.shape\n",
    "        if n <= 1:\n",
    "            return None, None\n",
    "\n",
    "        best_gain = -1\n",
    "        best_f, best_t = None, None\n",
    "        total_counts = np.bincount(y, minlength=self.n_classes_)\n",
    "        parent_gini = self._gini_impurity(total_counts)\n",
    "\n",
    "        for f in range(m):\n",
    "            idx = np.argsort(X[:, f])\n",
    "            x_sorted = X[idx, f]\n",
    "            y_sorted = y[idx]\n",
    "\n",
    "            left_counts = np.zeros(self.n_classes_, dtype=int)\n",
    "            right_counts = total_counts.copy()\n",
    "\n",
    "            for i in range(1, n):\n",
    "                if x_sorted[i] == x_sorted[i-1]:\n",
    "                    cls = y_sorted[i-1]\n",
    "                    left_counts[cls] += 1\n",
    "                    right_counts[cls] -= 1\n",
    "                    continue\n",
    "\n",
    "                cls = y_sorted[i-1]\n",
    "                left_counts[cls] += 1\n",
    "                right_counts[cls] -= 1\n",
    "\n",
    "                n_left, n_right = i, n - i\n",
    "                if n_left < self.min_samples_split or n_right < self.min_samples_split:\n",
    "                    continue\n",
    "\n",
    "                gini_left = self._gini_impurity(left_counts)\n",
    "                gini_right = self._gini_impurity(right_counts)\n",
    "                gini_split = (n_left * gini_left + n_right * gini_right) / n\n",
    "                gain = parent_gini - gini_split\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_f, best_t = f, (x_sorted[i] + x_sorted[i-1]) / 2.0\n",
    "\n",
    "        return (best_f, best_t) if best_gain > 1e-7 else (None, None)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n = len(y)\n",
    "        if n == 0:\n",
    "            return Node(value=0)\n",
    "\n",
    "        if len(np.unique(y)) == 1 or (self.max_depth is not None and depth >= self.max_depth):\n",
    "            return Node(value=int(np.bincount(y).argmax()))\n",
    "\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            return Node(value=int(np.bincount(y).argmax()))\n",
    "\n",
    "        mask = X[:, feature] <= threshold\n",
    "        left = self._build_tree(X[mask], y[mask], depth + 1)\n",
    "        right = self._build_tree(X[~mask], y[~mask], depth + 1)\n",
    "        return Node(feature=feature, threshold=threshold, left=left, right=right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y = np.asarray(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        self.n_classes_ = len(self.classes_)\n",
    "        self.tree_ = self._build_tree(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        preds = np.empty(len(X), dtype=int)\n",
    "        for i, x in enumerate(X):\n",
    "            node = self.tree_\n",
    "            while node.value is None:\n",
    "                node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "            preds[i] = node.value\n",
    "        return self.classes_[preds]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key in {'max_depth', 'min_samples_split'}:\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid parameter {key} for estimator MyDecisionTreeClassifier.\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc3ebb",
   "metadata": {},
   "source": [
    "# Реализация регрессора дерева решения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeRegressor:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "    def _mse_from_sums(self, sum_y, sum_sq_y, n):\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        return (sum_sq_y - (sum_y ** 2) / n) / n\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        n, m = X.shape\n",
    "        if n <= 1:\n",
    "            return None, None\n",
    "\n",
    "        best_mse = np.inf\n",
    "        best_f, best_t = None, None\n",
    "\n",
    "        total_sum = y.sum()\n",
    "        total_sq = np.dot(y, y)\n",
    "\n",
    "        for f in range(m):\n",
    "            idx = np.argsort(X[:, f])\n",
    "            x_sorted = X[idx, f]\n",
    "            y_sorted = y[idx]\n",
    "\n",
    "            sum_left = 0.0\n",
    "            sq_left = 0.0\n",
    "\n",
    "            for i in range(1, n):\n",
    "                y_val = y_sorted[i-1]\n",
    "                sum_left += y_val\n",
    "                sq_left += y_val * y_val\n",
    "\n",
    "                n_left, n_right = i, n - i\n",
    "                if n_left < self.min_samples_split or n_right < self.min_samples_split:\n",
    "                    continue\n",
    "\n",
    "                if x_sorted[i] == x_sorted[i-1]:\n",
    "                    continue\n",
    "\n",
    "                sum_right = total_sum - sum_left\n",
    "                sq_right = total_sq - sq_left\n",
    "\n",
    "                mse_left = self._mse_from_sums(sum_left, sq_left, n_left)\n",
    "                mse_right = self._mse_from_sums(sum_right, sq_right, n_right)\n",
    "                mse_split = (n_left * mse_left + n_right * mse_right) / n\n",
    "\n",
    "                if mse_split < best_mse:\n",
    "                    best_mse = mse_split\n",
    "                    best_f = f\n",
    "                    best_t = (x_sorted[i] + x_sorted[i-1]) / 2.0\n",
    "\n",
    "        return (best_f, best_t) if best_mse < np.inf else (None, None)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        n = len(y)\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or n < self.min_samples_split:\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        feature, threshold = self._best_split(X, y)\n",
    "        if feature is None:\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        mask = X[:, feature] <= threshold\n",
    "        left = self._build_tree(X[mask], y[mask], depth + 1)\n",
    "        right = self._build_tree(X[~mask], y[~mask], depth + 1)\n",
    "        return Node(feature=feature, threshold=threshold, left=left, right=right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = np.asarray(X, dtype=np.float32)\n",
    "        y = np.asarray(y, dtype=np.float32)\n",
    "        self.tree_ = self._build_tree(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.asarray(X)\n",
    "        preds = np.empty(len(X), dtype=np.float32)\n",
    "        for i, x in enumerate(X):\n",
    "            node = self.tree_\n",
    "            while node.value is None:\n",
    "                node = node.left if x[node.feature] <= node.threshold else node.right\n",
    "            preds[i] = node.value\n",
    "        return preds\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            'max_depth': self.max_depth,\n",
    "            'min_samples_split': self.min_samples_split\n",
    "        }\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        for key, value in params.items():\n",
    "            if key in {'max_depth', 'min_samples_split'}:\n",
    "                setattr(self, key, value)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid parameter {key} for estimator MyDecisionTreeClassifier.\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d052ca3",
   "metadata": {},
   "source": [
    "# Проверка классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e42378dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn accuracy=0.9597, f1=0.9595, recall=0.36363636363636365\n",
      "Custom  accuracy=0.9626, f1=0.9605, recall=0.3181818181818182\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('classification.csv')\n",
    "\n",
    "classification_X = df.drop('Bankrupt?', axis=1)\n",
    "classification_y = df['Bankrupt?']\n",
    "\n",
    "classification_X_train, classification_X_test, classification_y_train, classification_y_test = train_test_split(\n",
    "    classification_X, classification_y, test_size=0.2, random_state=42, stratify=classification_y\n",
    ")\n",
    "\n",
    "sk_clf = DecisionTreeClassifier()\n",
    "sk_clf.fit(classification_X_train, classification_y_train)\n",
    "classification_y_pred_sk = sk_clf.predict(classification_X_test)\n",
    "\n",
    "my_clf = MyDecisionTreeClassifier()\n",
    "my_clf.fit(classification_X_train, classification_y_train)\n",
    "classification_y_pred_my = my_clf.predict(classification_X_test)\n",
    "\n",
    "print(f\"Sklearn accuracy={accuracy_score(classification_y_test, classification_y_pred_sk):.4f}, f1={f1_score(classification_y_test, classification_y_pred_sk, average='weighted'):.4f}, recall={recall_score(classification_y_test, classification_y_pred_sk, pos_label=1)}\")\n",
    "print(f\"Custom  accuracy={accuracy_score(classification_y_test, classification_y_pred_my):.4f}, f1={f1_score(classification_y_test, classification_y_pred_my, average='weighted'):.4f}, recall={recall_score(classification_y_test, classification_y_pred_my, pos_label=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2acc2",
   "metadata": {},
   "source": [
    "# Провека регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec30859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn RMSE=51448.4117, R2=0.3094\n",
      "Custom  RMSE=47908.9323, R2=0.4011\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('regression.csv')\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "\n",
    "regression_X = df.drop(columns=['salary_in_usd', 'salary', 'salary_currency'], axis=1)\n",
    "regression_y = df['salary_in_usd'].to_numpy()\n",
    "\n",
    "regression_X = pd.get_dummies(regression_X, drop_first=True).to_numpy(dtype=np.float32)\n",
    "\n",
    "regression_X_train, regression_X_test, regression_y_train, regression_y_test = train_test_split(\n",
    "    regression_X, regression_y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "sk_reg = DecisionTreeRegressor()\n",
    "sk_reg.fit(regression_X_train, regression_y_train)\n",
    "regression_y_pred_sk = sk_reg.predict(regression_X_test)\n",
    "\n",
    "my_reg = MyDecisionTreeRegressor()\n",
    "my_reg.fit(regression_X_train, regression_y_train)\n",
    "regression_y_pred_my = my_reg.predict(regression_X_test)\n",
    "print(f\"SkLearn RMSE={np.sqrt(mean_squared_error(regression_y_test, regression_y_pred_sk)):.4f}, R2={r2_score(regression_y_test, regression_y_pred_sk):.4f}\")\n",
    "print(f\"Custom  RMSE={np.sqrt(mean_squared_error(regression_y_test, regression_y_pred_my)):.4f}, R2={r2_score(regression_y_test, regression_y_pred_my):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57b3b4e",
   "metadata": {},
   "source": [
    "### Улучшение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51de3d",
   "metadata": {},
   "source": [
    "### Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b3a11",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5748994",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(recall_score, pos_label=1)\n",
    "\n",
    "sk_param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'min_samples_leaf': [3, 5],\n",
    "    'class_weight': ['balanced', {0: 1, 1: 5}, {0: 1, 1: 10}],\n",
    "    'criterion': ['gini']\n",
    "}\n",
    "\n",
    "my_param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7],\n",
    "    'min_samples_split': [8, 10, 12]\n",
    "}\n",
    "\n",
    "classification_sk_grid = GridSearchCV(\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    sk_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "classification_sk_grid.fit(classification_X_train, classification_y_train)\n",
    "sk_best_clf = classification_sk_grid.best_estimator_\n",
    "\n",
    "classification_my_grid = GridSearchCV(\n",
    "    MyDecisionTreeClassifier(),\n",
    "    my_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "classification_my_grid.fit(classification_X_train, classification_y_train)\n",
    "my_best_clf = classification_my_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8c66d",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d087feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_y_pred_sk = sk_best_clf.predict(classification_X_test)\n",
    "\n",
    "classification_y_pred_my = my_best_clf.predict(classification_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39afe14",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46ac219d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn accuracy=0.8842, f1=0.9163, recall=0.7727272727272727\n",
      "Custom  accuracy=0.9677, f1=0.9648, recall=0.3409090909090909\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sklearn accuracy={accuracy_score(classification_y_test, classification_y_pred_sk):.4f}, f1={f1_score(classification_y_test, classification_y_pred_sk, average='weighted'):.4f}, recall={recall_score(classification_y_test, classification_y_pred_sk, pos_label=1)}\")\n",
    "print(f\"Custom  accuracy={accuracy_score(classification_y_test, classification_y_pred_my):.4f}, f1={f1_score(classification_y_test, classification_y_pred_my, average='weighted'):.4f}, recall={recall_score(classification_y_test, classification_y_pred_my, pos_label=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68e55f2",
   "metadata": {},
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0ca17",
   "metadata": {},
   "source": [
    "### Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53249b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(r2_score)\n",
    "\n",
    "sk_param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'min_samples_leaf': [3, 5]\n",
    "}\n",
    "\n",
    "my_param_grid = {\n",
    "    'max_depth': [4, 5, 6, 7],\n",
    "    'min_samples_split': [8, 10, 12]\n",
    "}\n",
    "\n",
    "regression_sk_grid = GridSearchCV(\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    sk_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "regression_sk_grid.fit(regression_X_train, regression_y_train)\n",
    "sk_best_reg = regression_sk_grid.best_estimator_\n",
    "\n",
    "regression_my_grid = GridSearchCV(\n",
    "    MyDecisionTreeRegressor(),\n",
    "    my_param_grid,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "regression_my_grid.fit(regression_X_train, regression_y_train)\n",
    "my_best_reg = regression_my_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d7a9c6",
   "metadata": {},
   "source": [
    "### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c64c096",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_y_pred_sk = sk_best_reg.predict(regression_X_test)\n",
    "\n",
    "regression_y_pred_my = my_best_reg.predict(regression_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165a2b06",
   "metadata": {},
   "source": [
    "### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5bc822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn RMSE=43917.1502, R2=0.4968\n",
      "Custom  RMSE=45480.9295, R2=0.4603\n"
     ]
    }
   ],
   "source": [
    "print(f\"SkLearn RMSE={np.sqrt(mean_squared_error(regression_y_test, regression_y_pred_sk)):.4f}, R2={r2_score(regression_y_test, regression_y_pred_sk):.4f}\")\n",
    "print(f\"Custom  RMSE={np.sqrt(mean_squared_error(regression_y_test, regression_y_pred_my)):.4f}, R2={r2_score(regression_y_test, regression_y_pred_my):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
