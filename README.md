
| ФИО                     | Днепров Стена Сергеевич |
|-------------------------|-------------------------|
| Группа                  | М8О-401Б-22             |

## Датасеты
Классификация: https://www.kaggle.com/datasets/fedesoriano/company-bankruptcy-prediction

Регрессия: https://www.kaggle.com/datasets/ruchi798/data-science-job-salaries

Оба датасета решают реальные задачи (первый позволяет предсказывать банкротство компаний, второй прикидывать зарплату в определенной области)


## ЛР1

Изначальные модели классификации из-за дают нулевой recal (тоесть все время выдают что компания не банкрот)

После скейлинга и уменьшения размерности recal становится равен 0.13636363636363635

С регрессией ситуация хуже: из-за того, что в основном признаки категориальные, улучшить ситуацию не удалось, даже после смены метрики расстояния и использования частотной кодировки. Но без настроек и препроцессинга мой регрессор показывает результаты лучше, чем регрессор sklearn

## ЛР2

Изначальные модели классификации из-за дают нулевой recal (тоесть все время выдают что компания не банкрот) это решается увеличением колличество итераций

После масштабирования и увеличения колличества итераций, а также уменьшение learning_rate увеличивает recal

В регресии скейлинг бесполезен из-за категориальных признаков, но переход на частотную кодировку даёт небольшой прирост r2 в sklearn

## ЛР3

Деревья решений изначально дают неплохие результаты, после подбора гиперпарамметров они становятся лучше

## ЛР4

Случайные леса изначально дают неплохие результаты, после подбора гиперпарамметров они становятся лучше

## ЛР5

Градиентный бустинг изначально даёт неплохие результаты, после скейлинга и подбора гиперпарамметров они становятся лучше